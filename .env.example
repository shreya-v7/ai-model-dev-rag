# Copy this file to .env and fill values.

LLM_PROVIDER=grok

GROK_API_KEY=your_grok_api_key_here
GROK_ENDPOINT=https://cmu-llm-api-resource.services.ai.azure.com/openai/v1/
GROK_MODEL=grok-3

AZURE_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_API_KEY=your_azure_api_key_here
AZURE_API_VERSION=2024-12-01-preview
AZURE_MODEL=o4-mini

GENERATION_TEMPERATURE=0.2
LLM_MAX_RETRIES=4
LLM_BACKOFF_BASE_S=1.0
LLM_BACKOFF_MAX_S=15.0
LLM_MIN_CALL_INTERVAL_S=0.5

EMBED_MODEL_NAME=all-MiniLM-L6-v2
CHUNK_SIZE_TOKENS=450
CHUNK_OVERLAP_TOKENS=100
WORDS_PER_TOKEN=0.75
TOP_K_PER_CLAIM=6

MAX_DOCUMENTS=10
UI_MIN_DOCS=10
UI_MAX_DOCS=20
MAX_UPLOAD_FILE_MB=25
